# Stanford CS236: Deep Generative Model

## 课程简介

- **先修要求**：深度学习，基础的随机过程，了解一点随机微分方程（SDE）和常微分方程（ODE）
- **参考教材**：[Deep Learning](https://www.deeplearningbook.org/)
- **主要内容**：
    - Autoregressive Model (AM)
    - Variational AutoEncoder (VAE)
    - Generative Adversarial Network (GAN)
    - Flow Models
    - Energy-Based Model (EBM)
    - Score-Based Model
    - Diffusion Model

这门课主要聚焦于生成式模型的三个方面：如何表示概率分布、如何计算两个概率分布之间的距离、如何评估生成式模型。你可以了解到生成式模型在近十年来的整体发展脉络，梳理出不同的生成式模型之间的区别以及联系。

这门课最大的优点在于前后的连贯性——我几乎是一气呵成的从 mixture Gaussian model 处“杀”到了 diffusion model。尽管在 [Umich 的计算机视觉课程](../computer-vision/EECS498.008.md) 中，我已经接触过 VAE、GAN 等模型，但是直到这门课程，我才明白原来 VAE 可以看作 mixture Gaussian 的无穷分类情形、DDPM 逐步加噪声的 motivation 又是来自 score-based model 的 denoising score matching 技术、GAN 的对抗训练又可以怎样应用到其他模型中……

不过，这门课的作业目前似乎只有 2018 版本的，最新的 2023 版本我暂未找到，如果你找到了，欢迎进行补充！

## 相关链接

1. 课程网站：<https://deepgenerativemodels.github.io/>
2. 课程视频：[Youtube](https://www.youtube.com/watch?v=XZ0PMRWXBEU&list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8>)
3. 课程作业：可在 GitHub 上找到 2018 年的作业（我暂时没有找到 2023 年的作业）
