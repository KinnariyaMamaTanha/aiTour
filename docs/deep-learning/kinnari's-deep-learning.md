# Kinnari çš„ä¸ªäººå­¦ä¹ è·¯çº¿

## è¯¾ç¨‹ç®€ä»‹

- **å…ˆä¿®è¦æ±‚**ï¼šçº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºï¼ŒPythonï¼Œç®—æ³•ï¼ŒçŸ©é˜µæ±‚å¯¼ï¼ˆå¯ä»¥å‚è€ƒ[çŸ©é˜µæ±‚å¯¼æœ¯](https://zhuanlan.zhihu.com/p/24709748)æˆ–è€…[è¿™ç¯‡ä¸“æ ](https://zhuanlan.zhihu.com/p/273729929)ï¼‰
- **å‚è€ƒææ–™**ï¼š
    - *Neural Networks and Deep Learning*, by Michael Nielsen
    - [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://zh-v2.d2l.ai/)ï¼Œä½œè€…ï¼šææ²ç­‰
    - ä¼—å¤šåšå®¢å’Œ Pytorch å®˜æ–¹æ•™ç¨‹
    - [GPT æ˜¯ä»€ä¹ˆï¼Ÿç›´è§‚è§£é‡Š Transformer | æ·±åº¦å­¦ä¹ ç¬¬ 5 ç« ](https://www.bilibili.com/video/BV13z421U7cs?vd_source=c9e11661823ca4062db1ef99f7e0eee1)å’Œ[ç›´è§‚è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformer çš„æ ¸å¿ƒ | æ·±åº¦å­¦ä¹ ç¬¬ 6 ç« ](https://www.bilibili.com/video/BV1TZ421j7Ke?vd_source=c9e11661823ca4062db1ef99f7e0eee1)ï¼Œåˆ›ä½œè€… 3Blue1Brown
- **ä¸»è¦å†…å®¹**ï¼š
    - å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œåå‘ä¼ æ’­ç®—æ³•ï¼ˆBPï¼‰
    - å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
    - å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼Œé—¨æ§è®°å¿†å•å…ƒï¼ˆGRUï¼‰ï¼Œé•¿çŸ­æœŸé€’å½’ç¥ç»ç½‘ç»œï¼ˆLSTMï¼‰ï¼Œæ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰ï¼ŒTransformerï¼Œè¯­è¨€æ¨¡å‹ï¼ˆlanguage modelï¼‰

## ä¸ªäººå¿ƒå¾—

æˆ‘é¦–å…ˆä½¿ç”¨ *Neural Networks and Deep Learning* è¿›è¡Œäº†æ·±åº¦å­¦ä¹ çš„å…¥é—¨ã€‚è¿™é—¨è¯¾æœ€å¤§çš„ä¼˜ç‚¹å°±æ˜¯é€šä¿—æ˜“æ‡‚ã€å¾ªåºæ¸è¿›ã€‚ä»æ„ŸçŸ¥æœºåˆ°ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ï¼Œå†åˆ°ä¸€ä¸ªä¸è¶…è¿‡ 5 è¡Œçš„å¤šå±‚æ„ŸçŸ¥æœºï¼Œè®©å®ƒå»è¯†åˆ«æ•°å­—ï¼Œç«Ÿç„¶èƒ½å¤Ÿè¾¾åˆ° 90% ä»¥ä¸Šçš„å‡†ç¡®åº¦ã€‚åœ¨è¿™ä¸ªæœ€ç®€å•çš„ç¥ç»ç½‘ç»œçš„åŸºç¡€ä¸Šï¼ŒMichael åˆä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è®²è¿°æ”¹è¿›å®ƒçš„è‹¥å¹²æ–¹æ³•ï¼Œä½ ä¼šä¸çŸ¥ä¸è§‰ä¸­å‘ç°ï¼Œè¿™ä¸€åˆ‡éƒ½æ˜¯é‚£ä¹ˆçš„è‡ªç„¶ä¸”è¿è´¯â€”â€”æŠŠå…ƒç´ è®¡ç®—è½¬åŒ–ä¸ºçŸ©é˜µè®¡ç®—ã€æŸå¤±å‡½æ•°çš„æ”¹è¿›ã€regularitionã€è¶…å‚æ•°çš„é€‰æ‹©â€¦â€¦ä½ ä¼šä¸€æ¬¡åˆä¸€æ¬¡çš„å‘ç°ï¼Œè¯†åˆ«æ•°å­—çš„å‡†ç¡®ç‡è¶Šæ¥è¶Šé«˜ï¼Œ95%ï¼Œ96.4%ï¼Œ97.3%ï¼Œä¸€åˆ‡ä¼¼ä¹éƒ½é‚£ä¹ˆé¼“èˆäººå¿ƒã€‚æœ€åä¸€ç« å¼•å…¥å·ç§¯ç¥ç»ç½‘ç»œï¼Œå†å‘Šè¯‰ä½ å…¶å®å…¨éƒ¨ä½¿ç”¨å…¨è¿æ¥å±‚ä¹Ÿæœ‰å±€é™ï¼Œè€Œä¸€äº›å·§å¦™çš„ç»“æ„å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›è¯†åˆ«çš„å‡†ç¡®ç‡ï¼ä»å§‹è‡³ç»ˆï¼Œæˆ‘ä»¬æ‰€åšçš„ä¸è¿‡åªæ˜¯ä¸€ä»¶äº‹æƒ…â€”â€”è¯†åˆ«æ•°å­—â€”â€”ä½†æ˜¯ï¼Œæˆ‘ä»¬ç«Ÿç„¶èµ°è¿‡äº†ä¸€ä¸ªç¥ç»ç½‘ç»œçš„å®Œæ•´æ­å»ºè¿‡ç¨‹ï¼ï¼ï¼å¦å¤–ï¼Œè¿™é—¨è¯¾è¿˜éå¸¸ç”ŸåŠ¨å½¢è±¡åœ°å‘ä½ å±•ç¤ºäº†å¤šå±‚æ„ŸçŸ¥æœºä¸­çš„åå‘ä¼ æ’­ç®—æ³•æ˜¯å¦‚ä½•å¾—æ¥çš„ã€ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œå¯ä»¥æ‹Ÿåˆä»»æ„å‡½æ•°ã€ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œéš¾ä»¥è®­ç»ƒï¼Œä»¥åŠåœ¨é™„å½•ä¸­è®¨è®ºçš„æ˜¯å¦æœ‰æ›´ç®€å•çš„â€œæ™ºèƒ½â€ã€‚è¿™äº›å†…å®¹åŒæ ·è®©æˆ‘å—ç›ŠåŒªæµ…ã€‚

æ¥ç€ï¼Œæˆ‘ä½¿ç”¨ Pytorch å®˜ç½‘ä¸Šçš„å‡ ç¯‡æ•™ç¨‹ä»¥åŠå…¶å®ƒçš„ä¸€äº›åšå®¢ï¼Œå­¦ä¹ äº† Pytorch çš„ä½¿ç”¨æ–¹æ³•å’Œ RNNã€GRUã€LSTMã€Attentionã€Transformerã€language model ç­‰å†…å®¹ï¼Œé¡ºåºå¦‚ä¸‹ï¼š

1. Pytorch å…¥é—¨æ•™ç¨‹ï¼š[Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)ã€‚åœ¨åç»­çš„å­¦ä¹ ä¸­ï¼Œå¯ä»¥å‚è€ƒæ›´è¯¦ç»†çš„æ•™ç¨‹ [Learn Pytorch](https://www.learnpytorch.io/)ã€‚
2. RNNã€GRUã€LSTM æ•™ç¨‹ï¼š
    1. [Written Memories: Understanding, Deriving and Extending the LSTM](https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html)ï¼Œè¿™ä¸ªæ•™ç¨‹æ˜¯æˆ‘çœ‹åˆ°è¿‡çš„å…³äº LSTM çš„å†™å¾—æœ€å¥½çš„æ•™ç¨‹ï¼Œä½œè€…ä»¥äººç±»é˜…è¯»ã€ç¿»è¯‘çš„ä¾‹å­ä½œä¸ºç±»æ¯”ï¼Œå½¢è±¡åœ°å±•ç¤ºå‡º LSTM äº§ç”Ÿè¿‡ç¨‹ä¸­çš„æ¯ä¸€ä¸ªåŠ¨æœºâ€”â€”å…ˆä» RNN å…¥æ‰‹ï¼Œç´§æ¥ç€åˆ†æå…¶ç¼ºé™·ï¼Œæå‡ºç”Ÿæ´»ä¸­çš„ä¾‹å­ï¼Œä»è€Œè¿›ä¸€æ­¥å¼€å‘å‡º LSTM çš„åŸå‹æœºï¼›å†æŒ‡å‡ºåŸå‹æœºåœ¨å®é™…ä¸­çš„è¡¨ç°ï¼Œå¹¶åˆ†æå…¶åŸå› ï¼Œåœ¨å¼¥è¡¥ç¼ºé™·çš„åŒæ—¶è‡ªç„¶çš„å¼•ç”³å‡ºä¸‰ç§è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­å°±åŒ…æ‹¬äº† GRU å’Œ pseudo LSTMï¼›æœ€åå°† pseudo LSTM ä¸åŸå§‹çš„ LSTM è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶æŒ‡å‡ºåŸå§‹ LSTM çš„ç¼ºé™·ä¸ä¼˜ç‚¹ï¼Œæ¥ç€æå‡ºä¸€ä¸ªèƒ½å¤Ÿåˆ©ç”¨åŸå§‹ LSTM ä¼˜ç‚¹çš„å˜ä½“ "The LSTM with peepholes"ã€‚åœ¨åšå®¢çš„æœ€åï¼Œä½œè€…è¿˜ä»‹ç»äº† LSTM çš„åŸºæœ¬æ€æƒ³åœ¨ residual networkã€highway network ä»¥åŠ Neural Turing Machine ä¸­çš„åº”ç”¨ï¼Œä½œä¸ºå¯¹ LSTM çš„æ‰©å±•å»¶ä¼¸ã€‚
    2. [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)ï¼Œ[ç°ä»£ç¥ç»å¾ªç¯ç½‘ç»œï¼ˆd2lï¼‰](https://zh-v2.d2l.ai/chapter_recurrent-modern/index.html)ï¼šåŒ…å«ä¸€äº›ç»“æ„çš„å¯è§†åŒ–ä»¥åŠä»£ç å®ç°ï¼Œå…·ä½“åˆ†æä¸Šå¹¶ä¸å¦‚ç¬¬ä¸€ç¯‡æ•™ç¨‹ï¼Œä¸è¿‡å¯ä»¥åŠ æ·±å°è±¡ã€‚
    3. [LONG SHORT-TERM MEMORY](https://www.bioinf.jku.at/publications/older/2604.pdf)ï¼šLSTM çš„åŸå§‹è®ºæ–‡ï¼Œæœ‰å…´è¶£çš„è¯å¯ä»¥çœ‹çœ‹
    4. [NLP From Scratch: Classifying Names with a Character-Level RNN](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)ï¼Œ[NLP From Scratch: Generating Names with a Character-Level RNN](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)ï¼šå­¦ä¹ ä½¿ç”¨ Pytorch å†™ä»£ç ï¼Œäº†è§£åŸºæœ¬æ¡†æ¶ã€‚å¦‚æœä½ éœ€è¦æœ‰å…³ tensorflow çš„ä»£ç æ•™ç¨‹çš„è¯ï¼Œå¯ä»¥çœ‹çœ‹ä¸Šé¢ 2.a ä¸­æ•™ç¨‹çš„ä½œè€…ç¬”ä¸‹ä¸‰ç¯‡æœ‰å…³ tensorflow å®ç°çš„åšå®¢ã€‚
3. Attention æ•™ç¨‹ï¼š
    1. [Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/)ï¼šä¸€ç¯‡è®²è¿° Attention çš„åšå®¢ï¼ŒååŠæ®µä»‹ç»äº† Transformer
    2. [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)ï¼šå¯è§†åŒ–åœ°å±•ç¤ºåœ¨ Neural Machine Translation ä¸­ Attention çš„ä½¿ç”¨ï¼Œç›´è§‚ä¸”å½¢è±¡ã€‚
    3. [d2l - æ³¨æ„åŠ›æœºåˆ¶](https://zh-v2.d2l.ai/chapter_attention-mechanisms/index.html)ï¼šåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ä¸­å…³äºæ³¨æ„åŠ›æœºåˆ¶çš„è®²è§£ï¼Œå¯ç»“åˆå…¶ä»£ç è¿›è¡Œå®è·µ
    4. [Illustrated: Self-Attention](https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF)ï¼šåŠ¨å›¾æ¼”ç¤º self-attentionï¼Œç›´è§‚å½¢è±¡
    5. [NLP From Scratch: Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)ï¼šå­¦ä¹ ä½¿ç”¨ Pytorch å†™ Attention æœºåˆ¶ã€‚
4. Transformer æ•™ç¨‹ï¼š
    1. [GPT æ˜¯ä»€ä¹ˆï¼Ÿç›´è§‚è§£é‡Š Transformer | æ·±åº¦å­¦ä¹ ç¬¬ 5 ç« ](https://www.bilibili.com/video/BV13z421U7cs?vd_source=c9e11661823ca4062db1ef99f7e0eee1)å’Œ[ç›´è§‚è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformer çš„æ ¸å¿ƒ | æ·±åº¦å­¦ä¹ ç¬¬ 6 ç« ](https://www.bilibili.com/video/BV1TZ421j7Ke?vd_source=c9e11661823ca4062db1ef99f7e0eee1)ï¼š3Blue1Brown çš„ç›´è§‚ç†è§£ GPT è§†é¢‘ï¼Œ<del>ä½¿æˆ‘æ³¨æ„åŠ›é›†ä¸­</del>ã€‚ç”±äºæ•´ä¸ªç³»åˆ—çš„è§†é¢‘è¿˜æ²¡æœ‰å…¨éƒ¨å…¬å¸ƒï¼Œæˆ‘åªæ”¾è¿™ä¸¤ä¸ªé“¾æ¥åœ¨è¿™é‡Œï¼Œåç»­ç»­é›†è¯·è‡ªè¡Œæœç´¢ã€‚
    2. [How Transformers Work](https://towardsdatascience.com/transformers-141e32e69591)ï¼šåœ¨è¿™ç¯‡åšå®¢çš„å‰åŠéƒ¨åˆ† RNNã€LSTM ç­‰æ¡†æ¶è¿›è¡Œäº†å›é¡¾ï¼Œåœ¨ååŠéƒ¨åˆ†ä»‹ç»äº† Transformer çš„å·¥ä½œåŸç†ã€‚å¦å¤–ï¼Œè¿™ç¯‡åšå®¢å¼•ç”¨äº†å¤§é‡å…¶å®ƒåšå®¢çš„å†…å®¹ï¼Œæ¨èéƒ½çœ‹ä¸€çœ‹ã€‚å…¶ä¸­ [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) è¿™ç¯‡åšå®¢å’Œ 3.d ä¸­çš„åšå®¢æ˜¯åŒä¸€ä¸ªä½œè€…å†™çš„ï¼Œéƒ½å…³äºå¯è§†åŒ–ï¼Œç›´è§‚ä¸”æ˜“äºç†è§£ã€‚
    3. [Transformer è®ºæ–‡é€æ®µç²¾è¯»](https://www.bilibili.com/video/BV1pu411o7BE?vd_source=c9e11661823ca4062db1ef99f7e0eee1)ï¼šææ²å¸¦ä½ é˜…è¯»ä¸€éå¤§åé¼é¼çš„ *Attention Is All You Need* è¿™ç¯‡è®ºæ–‡ï¼Œç›¸ä¿¡å¬å®Œåä½ å¯¹ transformer ä¼šæ›´åŠ ç†Ÿæ‚‰ã€‚æ²ç¥ä¸“é—¨æœ‰ä¸€ç³»åˆ—è§†é¢‘å¸¦é¢†é˜…è¯»è‘—åè®ºæ–‡ï¼Œæ„Ÿå…´è¶£çš„è¯å¯ä»¥éƒ½çœ‹çœ‹ã€‚
    4. [Tutorial 6: Transformers and Multi-Head Attention](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html)ï¼šä¸€ç¯‡ç»“åˆäº†ä»£ç è®²è§£ Transformer çš„åšå®¢ã€‚
    5. [Build your own Transformer from scratch using Pytorch](https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb)ï¼šå¸¦ä½ ä» 0 å¼€å§‹æ„å»ºä¸€ä¸ª Transformerï¼Œå’Œä¸Šä¸€ç¯‡åšå®¢ä¸€æ ·ï¼Œå¾ˆå€¼å¾—è·Ÿç€å†™å†™ä»£ç ã€‚
    6. [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)ï¼šè¯¦ç»†è®²è§£äº† Transformer çš„æ•°å­¦æ¡†æ¶ã€‚
    7. [The Transformer Family Version 2.0](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/)ï¼šè¯¦ç»†ä»‹ç»äº†ä¸€äº› Transformer çš„æ”¹è¿›ä¸å˜ä½“ï¼Œé€‚åˆç”¨äºæ‰©å±•è¿›é˜¶ã€‚
5. Language model æ•™ç¨‹ï¼š
    1. [A Comprehensive Guide to Build your own Language Model in Python!](https://medium.com/analytics-vidhya/a-comprehensive-guide-to-build-your-own-language-model-in-python-5141b3917d6d)ï¼šä¸€ç¯‡è¯¦å°½çš„ language model æ•™ç¨‹ã€‚
    2. [Language Modeling with LSTMs in PyTorch](https://towardsdatascience.com/language-modeling-with-lstms-in-pytorch-381a26badcbf): è¡¥å……è¯»ç‰©ã€‚
    3. [Word-level Language Modeling using RNN and Transformer](https://github.com/pytorch/examples/tree/main/word_language_model)ï¼šPyTorch å®˜æ–¹ä»£ç ç¤ºä¾‹ï¼Œå¯ä»¥ä½œä¸ºå‚è€ƒæ¥å†™ä¸€å†™ã€‚

åœ¨é˜…è¯»è¿™äº›æ•™ç¨‹çš„åŒæ—¶ï¼Œæˆ‘æ¨èåŒæ—¶é˜…è¯»[ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](./dive-into-deep-learning.md)è¿™æœ¬ä¹¦ã€‚å› ä¸ºä¸Šé¢åˆ—å‡ºçš„åšå®¢å¤§å¤šåå‘ç†è®ºï¼Œä»£ç ç¤ºä¾‹è¾ƒå°‘ï¼›è€Œè¿™æœ¬ä¹¦æ›´åŠ æ³¨é‡ä»£ç å®è·µï¼Œç†è®ºéƒ¨åˆ†åè€Œä¸æ˜¯å¾ˆè¯¦ç»†ã€‚å®ƒä»¬ä¸¤ä¸ªç»“åˆä¹‹åæ•ˆæœå°±æ¯”è¾ƒä¸é”™äº†ã€‚

æœ€åï¼Œç”±äºæˆ‘çš„è¿™ä»½è¯¾ç¨‹å…·æœ‰éå¸¸å¼ºçš„ä¸ªäººæ€§è´¨ï¼Œè€Œä¸” CV æ–¹å‘æ¶‰åŠå†…å®¹è¾ƒå°‘ï¼ˆä¸è¿‡åœ¨è®¡ç®—æœºè§†è§‰éƒ¨åˆ†ä¸­ä¼šæœ‰å¾ˆè¯¦å°½çš„è®²è§£ï¼‰ï¼Œè€Œ NLP æ–¹å‘å†…å®¹è¾ƒå¤šï¼Œæ‰€ä»¥ä½ å¯èƒ½æ›´éœ€è¦å…¶å®ƒçš„ä¸€äº›æ›´ç³»ç»Ÿçš„è¯¾ç¨‹ï¼Œä¾‹å¦‚ [CS230](./CS230.md)ï¼Œ[æå®æ¯…æœºå™¨å­¦ä¹ ](./æå®æ¯…æœºå™¨å­¦ä¹ .md)ç­‰ã€‚

## ç›¸å…³é“¾æ¥

1. [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)ï¼šä¸€ä¸ªç®€å•æ˜“æ‡‚çš„æ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼Œå›´ç»•ç€æ•°å­—è¯†åˆ«è¿™ä¸€æ·±åº¦å­¦ä¹ ä¸­çš„ç»å…¸é—®é¢˜ï¼Œå¸¦é¢†ä½ å­¦ä¼šå¤šå±‚æ„ŸçŸ¥æœºã€åå‘ä¼ æ’­ç®—æ³•ã€å·ç§¯ç¥ç»ç½‘ç»œã€‚
    1. <https://github.com/mnielsen/neural-networks-and-deep-learning>ï¼šä½œä¸šå’Œé—®é¢˜çš„ä»£ç å®ç°ï¼Œä½¿ç”¨ Python2
    2. <https://github.com/MichalDanielDobrzanski/DeepLearningPython>ï¼šç”±äº Python2 å·²ç»è¿‡æ—¶ï¼Œå› æ­¤æœ‰äººä½¿ç”¨ Python3 å®ç°äº† 2 ä¸­çš„ä»£ç ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä½¿ç”¨çš„ Theano åº“å¦‚ä»Šçœ‹æ¥ä¹Ÿæ˜¾å¾—è¿‡æ—¶äº†ã€‚
2. [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](./dive-into-deep-learning.md)ï¼šææ²å¤§ç¥å‡ºä¹¦ï¼Œç»“åˆäº†æ·±åº¦å­¦ä¹ ç†è®ºä¸ä»£ç ï¼Œä¸è¿‡ä¾§é‡äºä»£ç å®è·µã€‚å®ƒçš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯ä¹¦ä¸­çš„æ‰€æœ‰ä»£ç éƒ½å¯è¿è¡Œï¼Œæ­£å¦‚ä¹¦åæ‰€è¯´ï¼Œé€‚åˆä¸Šæ‰‹ç»ƒä¹ ã€‚ä¸è¿‡ä¸ªäººè®¤ä¸ºä¸å¤ªé€‚åˆå°ç™½å­¦ä¹ ï¼Œç»“åˆä¸Šè¿°åˆ—å‡ºçš„åšå®¢ä¸€èµ·å­¦ä¹ æ•ˆæœæ›´ä½³ã€‚

## é¸£è°¢

ä»¥ä¸Šæ•™ç¨‹/åšå®¢ä¸­å¤§å¤šæ¥æºäºæˆ‘çš„å¸ˆå…„ä»¬[@cpdu](https://github.com/cpdu)[@cantabile-kwok](https://github.com/cantabile-kwok)[@JamesZhutheThird](https://github.com/JamesZhutheThird)ï¼Œæ„Ÿè°¢å¸ˆå…„ä»¬å¯¹æˆ‘çš„æ— ç§å¸®åŠ©ï¼ğŸ™ğŸ™ğŸ™
