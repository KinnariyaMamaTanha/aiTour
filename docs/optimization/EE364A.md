# Stanford EE364A: Convex Optimization

## 课程简介

- **先修要求**：线性代数，高等数学
- **参考材料**：
    - [Convex Optimization](https://stanford.edu/~boyd/cvxbook/)：参考教材
    - [EE364a](https://stanford.edu/class/ee364a/index.html)：斯坦福大学的凸优化课程，由 [Stephen P. Boyd](https://stanford.edu/~boyd/) 讲授
- **主要内容**：
    - 凸集、凸函数、凸问题定义及基础性质
    - 凸优化算法，包括梯度下降、牛顿迭代法及其衍生算法

在当下的深度学习中，梯度下降几乎是无处不在的。如果你不满足于仅仅是调用 pytorch 等框架中的 API 而是想要深入了解梯度下降背后的原理，例如梯度下降在凸问题中为什么一定会收敛、收敛速度如何分析等，那么我推荐你学习一下凸优化这门课程。

另外，虽然这门课名字较为“高大上”，但是其实只是线性代数和高等数学在凸问题上的应用罢了，如果你有这两门先修课程较好的基础，那么学习这门课也并不会很难。

## 相关链接

1. 课程网站：<https://stanford.edu/class/ee364a/>
2. 视频：[Bilibili](https://www.bilibili.com/video/BV1aD4y1Q7aW/?spm_id_from=333.337.search-card.all.click&vd_source=4a4cf7e4efebbcaed2bfa6ad89728be8)
